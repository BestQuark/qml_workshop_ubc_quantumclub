{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning\n",
    "\n",
    "Machine learning is a subfield of artificial intelligence that focuses on developing algorithms and models that can learn patterns and make predictions or decisions based on data. It has become increasingly popular and important due to the growing availability of data and the need to analyze and draw insights from it.\n",
    "\n",
    "In this notebook, we'll explore some fundamental concepts of machine learning, such as:\n",
    "\n",
    "- Loading and exploring a dataset\n",
    "- Data preprocessing\n",
    "- Splitting data into training and test sets\n",
    "- Training a machine learning model\n",
    "- Model evaluation\n",
    "- Fine-tuning the model\n",
    "\n",
    "We will be using Python and some standard packages, like `numpy`, `matplotlib`, and `scikit-learn`, to demonstrate these concepts. Our goal is to provide an understanding of the machine learning pipeline and how to use popular libraries to build, train, and evaluate models.\n",
    "\n",
    "We will start by installing and importing the necessary packages, and then we'll load and explore the Iris dataset. After that, we'll preprocess the data, split it into training and test sets, and train a machine learning model using Support Vector Machines (SVM) with different kernel functions. Finally, we will evaluate our model's performance and explore different kernels to see how they affect the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy matplotlib scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "print(iris.DESCR)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the data and split in test and training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model and predict the unobserved values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(kernel='linear', C=1)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svm.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measure the performance of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try different Kernels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "results = {}\n",
    "\n",
    "for kernel in kernels:\n",
    "    svm = SVC(kernel=kernel, C=1)\n",
    "    svm.fit(X_train, y_train)\n",
    "    y_pred = svm.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    results[kernel] = accuracy\n",
    "\n",
    "print(\"Accuracy for Different Kernels:\")\n",
    "for kernel, accuracy in results.items():\n",
    "    print(f\"{kernel}: {accuracy:.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Kernel Comparison with Support Vector Machines\n",
    "\n",
    "In this exercise, you will compare the performance of two different kernel functions in a Support Vector Machine (SVM) classifier. Your task is to fit both kernels to a dataset, evaluate the models, and determine which kernel performs better.\n",
    "\n",
    "### Dataset Suggestions:\n",
    "\n",
    "- Iris dataset: A popular dataset for classification tasks that contains 150 samples of iris flowers, with four features (sepal length, sepal width, petal length, petal width) and three classes (setosa, versicolor, virginica). You can load this dataset from `sklearn.datasets` using `load_iris()`.\n",
    "- Wine dataset: A dataset containing 178 samples of wine, with 13 features (alcohol, malic acid, ash, etc.) and three classes (class 0, class 1, class 2). You can load this dataset from `sklearn.datasets` using `load_wine()`.\n",
    "- Breast cancer dataset: A dataset containing 569 samples of breast cancer tumors, with 30 features (mean radius, mean texture, mean perimeter, etc.) and two classes (malignant, benign). You can load this dataset from `sklearn.datasets` using `load_breast_cancer()`.\n",
    "\n",
    "### Instructions:\n",
    "\n",
    "1. Choose one of the suggested datasets or use a dataset of your choice.\n",
    "2. Load the dataset and explore its features and target classes.\n",
    "3. Preprocess the data (e.g., scale the features using `StandardScaler`).\n",
    "4. Split the data into training and test sets using train_test_split.\n",
    "5. Train two SVM classifiers with different kernel functions (e.g., 'linear' and 'rbf') using SVC.\n",
    "6. Evaluate the performance of each classifier on the test set using metrics like accuracy, precision, recall, and F1-score (use `accuracy_score`, `classification_report`, and other relevant functions from `sklearn.metrics`).\n",
    "7. Compare the performance of both classifiers and determine which kernel function performs better.\n",
    "\n",
    "### Hints:\n",
    "\n",
    "- When evaluating the models, consider not only accuracy but also other metrics, such as precision, recall, and F1-score, as they can provide a more comprehensive understanding of the model's performance.\n",
    "- You can use `GridSearchCV` or `RandomizedSearchCV` to fine-tune the hyperparameters of the SVM classifiers (e.g., the `C` parameter or the `gamma` parameter for the 'rbf' kernel).\n",
    "-If you'd like to experiment further, you can try additional kernel functions, such as 'poly' and 'sigmoid', or test the models on different datasets.\n",
    "-This exercise will help participants practice fitting SVM classifiers with different kernel functions, evaluating their performance, and comparing the results to choose the best kernel for a given dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your solution here"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
